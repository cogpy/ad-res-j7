# File Representation Validator
# Ensures every file has both markdown and JSON representations

name: File Representation Validator

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  validate-and-generate:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write      # Required to commit and push generated files
      actions: read        # Required to read workflow files
      checks: read         # Required to read check results
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install dependencies
        run: npm install glob

      - name: Create analysis script
        run: |
          cat > analyze-files.js << 'EOF'
          const fs = require('fs');
          const glob = require('glob');
          
          console.log('=== Repository File Analysis ===');
          
          // Find all files
          const mdFiles = glob.sync('**/*.md', { 
            ignore: ['node_modules/**', 'vendor/**', 'bower_components/**', 'jspm_packages/**', '.bundle/**', 'target/**', 'build/**', 'dist/**', '.git/**', 'README.md'] 
          });
          const jsonFiles = glob.sync('**/*.json', { 
            ignore: ['node_modules/**', 'vendor/**', 'bower_components/**', 'jspm_packages/**', '.bundle/**', 'target/**', 'build/**', 'dist/**', '.git/**', 'package*.json'] 
          });
          
          console.log(`üìä **File Statistics**`);
          console.log(`- Markdown files: ${mdFiles.length}`);
          console.log(`- JSON files: ${jsonFiles.length}`);
          console.log('');
          
          // Check for missing pairs
          let missing_json = 0;
          let missing_md = 0;
          let missingJsonList = [];
          let missingMdList = [];
          
          console.log('üîç **Missing JSON representations:**');
          for (const mdFile of mdFiles) {
            const jsonFile = mdFile.replace(/\.md$/, '.json');
            if (!fs.existsSync(jsonFile)) {
              console.log(`- \`${jsonFile}\` (for \`${mdFile}\`)`);
              missingJsonList.push({md: mdFile, json: jsonFile});
              missing_json++;
            }
          }
          
          if (missing_json === 0) {
            console.log('- ‚úÖ All markdown files have JSON representations');
          }
          
          console.log('');
          console.log('üîç **Missing Markdown representations:**');
          for (const jsonFile of jsonFiles) {
            const mdFile = jsonFile.replace(/\.json$/, '.md');
            if (!fs.existsSync(mdFile)) {
              console.log(`- \`${mdFile}\` (for \`${jsonFile}\`)`);
              missingMdList.push({json: jsonFile, md: mdFile});
              missing_md++;
            }
          }
          
          if (missing_md === 0) {
            console.log('- ‚úÖ All JSON files have markdown representations');
          }
          
          console.log('');
          console.log('üìà **Summary:**');
          console.log(`- Missing JSON files: ${missing_json}`);
          console.log(`- Missing MD files: ${missing_md}`);
          
          // Write outputs for GitHub Actions
          fs.writeFileSync('missing_json_count.txt', missing_json.toString());
          fs.writeFileSync('missing_md_count.txt', missing_md.toString());
          
          console.log(`\nAnalysis complete. Missing pairs: JSON=${missing_json}, MD=${missing_md}`);
          EOF

      - name: Analyze existing file representations
        id: analyze
        run: |
          echo "=== Repository File Analysis ===" >> $GITHUB_STEP_SUMMARY
          node analyze-files.js >> $GITHUB_STEP_SUMMARY
          
          # Read the counts from files created by Node.js script  
          missing_json=$(cat missing_json_count.txt)
          missing_md=$(cat missing_md_count.txt)
          
          echo "missing_json=$missing_json" >> $GITHUB_OUTPUT
          echo "missing_md=$missing_md" >> $GITHUB_OUTPUT

      - name: Create file converter script
        run: |
          cat > file-converter.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const glob = require('glob');

          class FileConverter {
            constructor() {
              this.conversions = 0;
            }

            // Convert markdown content to structured JSON
            markdownToJson(mdContent, filePath) {
              const lines = mdContent.split('\n');
              const result = {
                title: '',
                source_file: path.resolve(filePath),
                created_at: new Date().toISOString(),
                file_type: 'markdown',
                sections: []
              };

              let currentSection = null;
              let currentSubsection = null;
              let currentContent = [];

              for (const line of lines) {
                // Extract title from first heading
                if (line.match(/^#\s+/) && !result.title) {
                  result.title = line.substring(1).trim();
                  continue;
                }

                // Handle headings
                const headingMatch = line.match(/^(#{1,6})\s+(.*)$/);
                if (headingMatch) {
                  const level = headingMatch[1].length;
                  const heading = headingMatch[2].trim();

                  // Save previous content
                  if (currentSubsection) {
                    currentSubsection.content = currentContent.join('\n').trim();
                  } else if (currentSection) {
                    currentSection.content = currentContent.join('\n').trim();
                  }
                  currentContent = [];

                  if (level === 2) {
                    // New main section
                    if (currentSection) {
                      result.sections.push(currentSection);
                    }
                    currentSection = {
                      heading: heading,
                      level: level,
                      content: '',
                      subsections: []
                    };
                    currentSubsection = null;
                  } else if (level >= 3 && currentSection) {
                    // New subsection
                    if (currentSubsection) {
                      currentSection.subsections.push(currentSubsection);
                    }
                    currentSubsection = {
                      heading: heading,
                      level: level,
                      content: ''
                    };
                  }
                } else {
                  // Regular content line
                  currentContent.push(line);
                }
              }

              // Save final content
              if (currentSubsection) {
                currentSubsection.content = currentContent.join('\n').trim();
                if (currentSection) currentSection.subsections.push(currentSubsection);
              } else if (currentSection) {
                currentSection.content = currentContent.join('\n').trim();
              }

              if (currentSection) {
                result.sections.push(currentSection);
              }

              // If no structured sections found, put all content in a single section
              if (result.sections.length === 0 && lines.length > 0) {
                result.sections.push({
                  heading: result.title || 'Document Content',
                  level: 2,
                  content: lines.join('\n').trim(),
                  subsections: []
                });
              }

              return result;
            }

            // Convert JSON content to markdown
            jsonToMarkdown(jsonContent) {
              let markdown = '';
              
              try {
                const data = typeof jsonContent === 'string' ? JSON.parse(jsonContent) : jsonContent;
                
                // Add title
                if (data.title) {
                  markdown += `# ${data.title}\n\n`;
                }

                // Add metadata if it's a converted file
                if (data.source_file || data.created_at) {
                  markdown += `<!-- Generated from JSON representation -->\n`;
                  if (data.source_file) markdown += `<!-- Source: ${data.source_file} -->\n`;
                  if (data.created_at) markdown += `<!-- Created: ${data.created_at} -->\n`;
                  markdown += `\n`;
                }

                // Add sections
                if (data.sections && Array.isArray(data.sections)) {
                  for (const section of data.sections) {
                    if (section.heading) {
                      const level = section.level || 2;
                      markdown += `${'#'.repeat(level)} ${section.heading}\n\n`;
                    }
                    
                    if (section.content) {
                      markdown += `${section.content}\n\n`;
                    }

                    // Add subsections
                    if (section.subsections && Array.isArray(section.subsections)) {
                      for (const subsection of section.subsections) {
                        if (subsection.heading) {
                          const level = subsection.level || 3;
                          markdown += `${'#'.repeat(level)} ${subsection.heading}\n\n`;
                        }
                        if (subsection.content) {
                          markdown += `${subsection.content}\n\n`;
                        }
                      }
                    }
                  }
                } else {
                  // Fallback: show JSON as code block
                  markdown += `## Data\n\n\`\`\`json\n${JSON.stringify(data, null, 2)}\n\`\`\`\n\n`;
                }

                return markdown;
              } catch (error) {
                console.error('JSON parsing error:', error);
                // Fallback for invalid JSON
                return `# JSON Document\n\n\`\`\`json\n${jsonContent}\n\`\`\`\n`;
              }
            }

            // Process all files and generate missing representations
            processFiles() {
              console.log('üîÑ Starting file conversion process...');
              
              // Find all files
              const mdFiles = glob.sync('**/*.md', { 
                ignore: ['node_modules/**', 'vendor/**', 'bower_components/**', 'jspm_packages/**', '.bundle/**', 'target/**', 'build/**', 'dist/**', '.git/**', 'README.md'] 
              });
              const jsonFiles = glob.sync('**/*.json', { 
                ignore: ['node_modules/**', 'vendor/**', 'bower_components/**', 'jspm_packages/**', '.bundle/**', 'target/**', 'build/**', 'dist/**', '.git/**', 'package*.json'] 
              });

              console.log(`Found ${mdFiles.length} markdown files and ${jsonFiles.length} JSON files`);

              // Convert MD to JSON for missing JSON files
              for (const mdFile of mdFiles) {
                const jsonFile = mdFile.replace(/\.md$/, '.json');
                if (!fs.existsSync(jsonFile)) {
                  try {
                    const mdContent = fs.readFileSync(mdFile, 'utf8');
                    const jsonData = this.markdownToJson(mdContent, mdFile);
                    
                    // Ensure directory exists
                    const dir = path.dirname(jsonFile);
                    if (!fs.existsSync(dir)) {
                      fs.mkdirSync(dir, { recursive: true });
                    }
                    
                    fs.writeFileSync(jsonFile, JSON.stringify(jsonData, null, 2));
                    console.log(`‚úÖ Generated JSON: ${jsonFile}`);
                    this.conversions++;
                  } catch (error) {
                    console.error(`‚ùå Error converting ${mdFile}:`, error.message);
                  }
                }
              }

              // Convert JSON to MD for missing MD files
              for (const jsonFile of jsonFiles) {
                const mdFile = jsonFile.replace(/\.json$/, '.md');
                if (!fs.existsSync(mdFile)) {
                  try {
                    const jsonContent = fs.readFileSync(jsonFile, 'utf8');
                    const mdData = this.jsonToMarkdown(jsonContent);
                    
                    // Ensure directory exists
                    const dir = path.dirname(mdFile);
                    if (!fs.existsSync(dir)) {
                      fs.mkdirSync(dir, { recursive: true });
                    }
                    
                    fs.writeFileSync(mdFile, mdData);
                    console.log(`‚úÖ Generated MD: ${mdFile}`);
                    this.conversions++;
                  } catch (error) {
                    console.error(`‚ùå Error converting ${jsonFile}:`, error.message);
                  }
                }
              }

              return this.conversions;
            }
          }

          // Run the conversion
          const converter = new FileConverter();
          const totalConversions = converter.processFiles();
          console.log(`\nüéâ Conversion complete! Generated ${totalConversions} files.`);

          // Exit with appropriate code
          process.exit(0);
          EOF

      - name: Generate missing file representations
        run: |
          echo "üöÄ Generating missing file representations..."
          node file-converter.js

      - name: Configure Git
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      - name: Commit and push changes
        run: |
          # Check if there are any changes
          if git diff --quiet && git diff --staged --quiet; then
            echo "‚úÖ No new files needed - all representations already exist!"
            echo "status=no-changes" >> $GITHUB_ENV
          else
            git add -A
            git status
            
            # Count the changes
            added_files=$(git diff --staged --name-only | wc -l)
            
            echo "üìù Committing $added_files new file representations..."
            git commit -m "Auto-generate missing file representations
            
            - Generated JSON representations for markdown files
            - Generated markdown representations for JSON files
            - Ensures every file has both MD and JSON formats
            - Files processed: $added_files
            - Automated by GitHub Actions"
            
            echo "status=committed" >> $GITHUB_ENV
            echo "files_added=$added_files" >> $GITHUB_ENV
          fi

      - name: Final validation and summary
        run: |
          cat > final-validation.js << 'EOF'
          const fs = require('fs');
          const glob = require('glob');
          
          console.log('=== Final Repository Analysis ===');
          
          // Find all files
          const mdFiles = glob.sync('**/*.md', { 
            ignore: ['node_modules/**', 'vendor/**', 'bower_components/**', 'jspm_packages/**', '.bundle/**', 'target/**', 'build/**', 'dist/**', '.git/**', 'README.md'] 
          });
          const jsonFiles = glob.sync('**/*.json', { 
            ignore: ['node_modules/**', 'vendor/**', 'bower_components/**', 'jspm_packages/**', '.bundle/**', 'target/**', 'build/**', 'dist/**', '.git/**', 'package*.json'] 
          });
          
          console.log('');
          console.log('üìä **Final Statistics**');
          console.log(`- Total Markdown files: ${mdFiles.length}`);
          console.log(`- Total JSON files: ${jsonFiles.length}`);
          console.log('');
          
          // Final validation check
          let missing_pairs = 0;
          
          for (const mdFile of mdFiles) {
            const jsonFile = mdFile.replace(/\.md$/, '.json');
            if (!fs.existsSync(jsonFile)) {
              console.log(`‚ùå Still missing JSON: ${jsonFile}`);
              missing_pairs++;
            }
          }
          
          for (const jsonFile of jsonFiles) {
            const mdFile = jsonFile.replace(/\.json$/, '.md');
            if (!fs.existsSync(mdFile)) {
              console.log(`‚ùå Still missing MD: ${mdFile}`);
              missing_pairs++;
            }
          }
          
          if (missing_pairs === 0) {
            console.log('‚úÖ **SUCCESS**: All files have both markdown and JSON representations!');
            console.log('');
            console.log('üéØ **Repository Compliance**: 100%');
            process.exit(0);
          } else {
            console.log(`‚ùå **WARNING**: ${missing_pairs} files still missing their counterpart`);
            console.log('');
            console.log('This may indicate an issue with the conversion process.');
            process.exit(1);
          }
          EOF
          
          echo "=== Final Repository Analysis ===" >> $GITHUB_STEP_SUMMARY
          node final-validation.js >> $GITHUB_STEP_SUMMARY

  ocr-and-generate-missing-representations:
    needs: validate-and-generate
    runs-on: ubuntu-latest
    
    permissions:
      contents: write      # Required to commit and push generated files
      actions: read        # Required to read workflow files
      checks: read         # Required to read check results
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js and OCR dependencies
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Install Node.js dependencies
        run: npm install glob

      - name: Install OCR dependencies
        run: sudo apt-get update && sudo apt-get install -y tesseract-ocr

      - name: Create OCR file converter script
        run: |
          cat > ocr-file-converter.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const glob = require('glob');
          const { execSync } = require('child_process');

          class OCRFileConverter {
            constructor() {
              this.conversions = 0;
              this.ocrGenerated = 0;
            }

            // Convert markdown content to structured JSON (reuse from main converter)
            markdownToJson(mdContent, filePath) {
              const lines = mdContent.split('\n');
              const result = {
                title: '',
                source_file: path.resolve(filePath),
                created_at: new Date().toISOString(),
                file_type: 'markdown',
                generated_via: 'ocr',
                sections: []
              };

              let currentSection = null;
              let currentSubsection = null;
              let currentContent = [];

              for (const line of lines) {
                // Extract title from first heading
                if (line.match(/^#\s+/) && !result.title) {
                  result.title = line.substring(1).trim();
                  continue;
                }

                // Handle headings
                const headingMatch = line.match(/^(#{1,6})\s+(.*)$/);
                if (headingMatch) {
                  const level = headingMatch[1].length;
                  const heading = headingMatch[2].trim();

                  // Save previous content
                  if (currentSubsection) {
                    currentSubsection.content = currentContent.join('\n').trim();
                  } else if (currentSection) {
                    currentSection.content = currentContent.join('\n').trim();
                  }
                  currentContent = [];

                  if (level === 2) {
                    // New main section
                    if (currentSection) {
                      result.sections.push(currentSection);
                    }
                    currentSection = {
                      heading: heading,
                      level: level,
                      content: '',
                      subsections: []
                    };
                    currentSubsection = null;
                  } else if (level >= 3 && currentSection) {
                    // New subsection
                    if (currentSubsection) {
                      currentSection.subsections.push(currentSubsection);
                    }
                    currentSubsection = {
                      heading: heading,
                      level: level,
                      content: ''
                    };
                  }
                } else {
                  // Regular content line
                  currentContent.push(line);
                }
              }

              // Save final content
              if (currentSubsection) {
                currentSubsection.content = currentContent.join('\n').trim();
                if (currentSection) currentSection.subsections.push(currentSubsection);
              } else if (currentSection) {
                currentSection.content = currentContent.join('\n').trim();
              }

              if (currentSection) {
                result.sections.push(currentSection);
              }

              // If no structured sections found, put all content in a single section
              if (result.sections.length === 0 && lines.length > 0) {
                result.sections.push({
                  heading: result.title || 'OCR Document Content',
                  level: 2,
                  content: lines.join('\n').trim(),
                  subsections: []
                });
              }

              return result;
            }

            // Perform OCR on image file
            performOCR(imagePath) {
              try {
                const baseName = path.basename(imagePath, path.extname(imagePath));
                const tempTxtFile = `/tmp/${baseName}.txt`;
                
                console.log(`üß† Performing OCR on: ${imagePath}`);
                
                // Run tesseract OCR
                execSync(`tesseract "${imagePath}" "/tmp/${baseName}" --dpi 300 -l eng`, { stdio: 'pipe' });
                
                if (fs.existsSync(tempTxtFile)) {
                  const ocrText = fs.readFileSync(tempTxtFile, 'utf8').trim();
                  fs.unlinkSync(tempTxtFile); // Clean up temp file
                  
                  if (ocrText.length > 0) {
                    return ocrText;
                  }
                }
                return null;
              } catch (error) {
                console.error(`‚ùå OCR failed for ${imagePath}:`, error.message);
                return null;
              }
            }

            // Process image files for missing representations
            processImageFiles() {
              console.log('üîÑ Processing image files for OCR conversion...');
              
              // Find all image files
              const imageFiles = glob.sync('**/*.{png,jpg,jpeg,gif,bmp}', { 
                ignore: ['node_modules/**', 'vendor/**', 'bower_components/**', 'jspm_packages/**', '.bundle/**', 'target/**', 'build/**', 'dist/**', '.git/**'] 
              });

              console.log(`Found ${imageFiles.length} image files`);

              if (imageFiles.length === 0) {
                console.log('‚ÑπÔ∏è  No image files found - OCR processing not needed');
                return 0;
              }

              for (const imageFile of imageFiles) {
                const baseName = imageFile.replace(/\.(png|jpg|jpeg|gif|bmp)$/i, '');
                const mdFile = `${baseName}.md`;
                const jsonFile = `${baseName}.json`;

                let ocrText = null;

                // Generate missing Markdown file via OCR
                if (!fs.existsSync(mdFile)) {
                  ocrText = ocrText || this.performOCR(imageFile);
                  if (ocrText) {
                    try {
                      // Create markdown content with OCR text
                      const mdContent = `# ${path.basename(baseName)}\n\n<!-- Generated via OCR from ${imageFile} -->\n<!-- Created: ${new Date().toISOString()} -->\n\n## OCR Content\n\n${ocrText}\n`;
                      
                      // Ensure directory exists
                      const dir = path.dirname(mdFile);
                      if (!fs.existsSync(dir)) {
                        fs.mkdirSync(dir, { recursive: true });
                      }
                      
                      fs.writeFileSync(mdFile, mdContent);
                      console.log(`‚úÖ Generated Markdown via OCR: ${mdFile}`);
                      this.ocrGenerated++;
                    } catch (error) {
                      console.error(`‚ùå Error creating markdown file ${mdFile}:`, error.message);
                    }
                  }
                }

                // Generate missing JSON file via OCR + conversion
                if (!fs.existsSync(jsonFile)) {
                  ocrText = ocrText || this.performOCR(imageFile);
                  if (ocrText) {
                    try {
                      // Create markdown content first
                      const tempMdContent = `# ${path.basename(baseName)}\n\n## OCR Content\n\n${ocrText}\n`;
                      
                      // Convert to JSON structure
                      const jsonData = this.markdownToJson(tempMdContent, imageFile);
                      
                      // Ensure directory exists
                      const dir = path.dirname(jsonFile);
                      if (!fs.existsSync(dir)) {
                        fs.mkdirSync(dir, { recursive: true });
                      }
                      
                      fs.writeFileSync(jsonFile, JSON.stringify(jsonData, null, 2));
                      console.log(`‚úÖ Generated JSON via OCR: ${jsonFile}`);
                      this.ocrGenerated++;
                    } catch (error) {
                      console.error(`‚ùå Error creating JSON file ${jsonFile}:`, error.message);
                    }
                  }
                }
              }

              return this.ocrGenerated;
            }
          }

          // Run the OCR conversion
          const converter = new OCRFileConverter();
          const totalGenerated = converter.processImageFiles();
          console.log(`\nüéâ OCR processing complete! Generated ${totalGenerated} files from images.`);

          // Exit with appropriate code
          process.exit(0);
          EOF

      - name: Run OCR/Conversion for Missing Markdown/JSON
        run: |
          echo "üöÄ Running OCR processing for image files..."
          node ocr-file-converter.js

      - name: Configure Git
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      - name: Commit and push OCR-generated files
        run: |
          # Check if there are any changes
          if git diff --quiet && git diff --staged --quiet; then
            echo "‚úÖ No OCR files needed - all image representations already exist or no images found!"
            echo "ocr_status=no-changes" >> $GITHUB_ENV
          else
            git add -A
            git status
            
            # Count the changes
            ocr_files=$(git diff --staged --name-only | wc -l)
            
            echo "üìù Committing $ocr_files OCR-generated file representations..."
            git commit -m "Auto-generate missing Markdown/JSON files via OCR/conversion
            
            - Generated Markdown representations from image OCR
            - Generated JSON representations from image OCR + conversion  
            - Ensures image assets have text representations via OCR
            - Files processed: $ocr_files
            - Automated by GitHub Actions OCR workflow"
            
            echo "ocr_status=committed" >> $GITHUB_ENV
            echo "ocr_files_added=$ocr_files" >> $GITHUB_ENV
            
            git push
          fi

      - name: Final OCR validation and summary
        run: |
          echo "=== OCR Processing Summary ===" >> $GITHUB_STEP_SUMMARY
          
          # Count image files and their representations
          image_count=$(find . -type f \( -name "*.png" -o -name "*.jpg" -o -name "*.jpeg" -o -name "*.gif" -o -name "*.bmp" \) -not -path "./.git/*" -not -path "./node_modules/*" -not -path "./vendor/*" -not -path "./bower_components/*" -not -path "./jspm_packages/*" -not -path "./.bundle/*" -not -path "./target/*" -not -path "./build/*" -not -path "./dist/*" | wc -l)
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üìä **OCR Processing Results**" >> $GITHUB_STEP_SUMMARY
          echo "- Total image files found: $image_count" >> $GITHUB_STEP_SUMMARY
          
          if [ $image_count -eq 0 ]; then
            echo "- ‚úÖ No image files found - OCR processing not required" >> $GITHUB_STEP_SUMMARY
          else
            echo "- üß† OCR processing completed for image assets" >> $GITHUB_STEP_SUMMARY
            echo "- üìù Generated text representations via Tesseract OCR" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üéØ **Adaptive Job Addition**: Successfully implemented OCR-based generation" >> $GITHUB_STEP_SUMMARY
          echo "üìà **Cognitive Flowchart Compliance**: Recursive implementation pathway completed" >> $GITHUB_STEP_SUMMARY

      - name: Report workflow failures
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Gather failure information
            const failureContext = {
              workflow: 'file-representations',
              job: context.job,
              trigger: context.eventName,
              branch: context.ref,
              commit: context.sha,
              actor: context.actor,
              runId: context.runId,
              runUrl: `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`,
              timestamp: new Date().toISOString(),
              repository: `${context.repo.owner}/${context.repo.repo}`
            };
            
            // Determine which job failed and gather relevant context
            let jobSpecificInfo = '';
            let impactAssessment = '';
            
            if (context.job === 'validate-and-generate') {
              jobSpecificInfo = `
              ### Validate-and-Generate Job Failure
              This job handles:
              - File analysis and validation
              - Markdown to JSON conversion
              - JSON to Markdown conversion
              - File structure compliance checking
              `;
              impactAssessment = `
              ### Impact Assessment
              - ‚ö†Ô∏è **Critical**: File representations may be missing or outdated
              - ‚ö†Ô∏è **Documentation**: Cross-format file consistency may be compromised  
              - ‚ö†Ô∏è **Compliance**: Repository structure requirements may not be met
              `;
            } else if (context.job === 'ocr-missing-representations') {
              jobSpecificInfo = `
              ### OCR Job Failure
              This job handles:
              - OCR processing of image files
              - Generation of text representations from images
              - Automated conversion of visual content to accessible formats
              `;
              impactAssessment = `
              ### Impact Assessment
              - ‚ö†Ô∏è **Accessibility**: Image content may not have text representations
              - ‚ö†Ô∏è **Content**: Visual information may not be searchable/accessible
              - ‚ö†Ô∏è **OCR**: Automated text extraction from images is failing
              `;
            }
            
            // Create failure issue
            const issueTitle = `File-Representations Workflow Failure - ${failureContext.timestamp.split('T')[0]}`;
            const issueBody = `## üö® Workflow Failure Alert
            
            The **file-representations** workflow has failed and requires immediate attention.
            
            ### Failure Details
            - **Workflow**: ${failureContext.workflow}
            - **Failed Job**: ${failureContext.job}
            - **Trigger**: ${failureContext.trigger}
            - **Branch**: ${failureContext.branch}
            - **Commit**: ${failureContext.commit}
            - **Actor**: ${failureContext.actor}
            - **Timestamp**: ${failureContext.timestamp}
            
            ${jobSpecificInfo}
            
            ${impactAssessment}
            
            ### Immediate Actions Required
            1. üîç **Investigate**: Check the workflow run logs: [View Run](${failureContext.runUrl})
            2. üîß **Diagnose**: 
               - For validate-and-generate: Check file permissions and Node.js script errors
               - For OCR job: Verify Tesseract installation and image file accessibility
            3. üß™ **Test**: Run workflow manually after fixes
            4. üìã **Verify**: Ensure file conversions are working properly
            
            ### Common Failure Scenarios
            - **Permission Issues**: Git commit/push failures due to insufficient permissions
            - **Script Errors**: JavaScript syntax or runtime errors in conversion scripts
            - **OCR Failures**: Tesseract OCR installation or image processing issues
            - **File Access**: Unable to read/write files due to path or permission issues
            - **Network Issues**: Git operations failing due to connectivity
            
            ### Monitoring Information
            - **Workflow Run**: [${failureContext.runId}](${failureContext.runUrl})
            - **Repository**: ${failureContext.repository}
            - **Triggered by**: ${failureContext.trigger}
            
            ---
            
            *This issue was created automatically by the workflow monitoring system. Please investigate and resolve the failure promptly.*
            `;
            
            // Check for existing failure issues to prevent spam
            const existingIssues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: ['workflow-failure', 'file-representations'],
              per_page: 5
            });
            
            const recentFailure = existingIssues.data.find(issue => {
              const issueDate = new Date(issue.created_at);
              const hoursSinceIssue = (new Date() - issueDate) / (1000 * 60 * 60);
              return hoursSinceIssue < 24; // Only check last 24 hours
            });
            
            if (!recentFailure) {
              const newIssue = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: issueTitle,
                body: issueBody,
                labels: ['workflow-failure', 'file-representations', 'bug', 'priority: high']
              });
              
              console.log(`Created failure alert issue: ${newIssue.data.html_url}`);
            } else {
              // Add comment to existing issue instead of creating new one
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: recentFailure.number,
                body: `## üîÑ Additional Failure Detected
                
                Another failure occurred in the file-representations workflow.
                
                **Time**: ${failureContext.timestamp}
                **Job**: ${failureContext.job}
                **Trigger**: ${failureContext.trigger}  
                **Run**: [${failureContext.runId}](${failureContext.runUrl})
                
                Please investigate this recurring failure pattern.`
              });
              
              console.log(`Added comment to existing failure issue: ${recentFailure.html_url}`);
            }